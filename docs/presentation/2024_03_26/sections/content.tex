\begin{frame}{Problem considered}
	\vspace{5pt}
    \begin{minipage}{0.7\linewidth}
    	\textbf{Poisson problem with Dirichlet conditions :} \\
    	Find $u : \Omega \rightarrow \mathbb{R}^d (d=1,2,3)$ such that
    	\vspace{-10pt}
    	\begin{equation*}
    		\left\{\begin{aligned}
    			&-\Delta u(X) = f(X) \quad \text{in } \Omega, \\
    			&u(X) = g(X) \quad \text{on } \partial \Omega
    		\end{aligned}\right. \label{edp}
    	\end{equation*}
    \end{minipage}
	\begin{minipage}{0.26\linewidth}
		\vspace{-20pt}
		\pgfimage[width=\linewidth]{images/content/geometries.png}
	\end{minipage}
	
	with $\Delta$ the Laplace operator, $\Omega$ a smooth bounded open set and $\Gamma$ its boundary. 
	
	For the following examples, we will consider $f(X)=1$ and $g(X)=0$.
	
	\vspace{5pt}
	
	\textbf{Standard PINNs :} We are looking for $\theta_u$ such that
	\begin{equation*}
		\theta_u = \argmin_{\theta} w_{r}\; J_{r}(\theta)+w_{bc}\; J_{bc}(\theta)
	\end{equation*}
	where $w_{r}$ and $w_{bc}$ are the respective weights associated with
	\begin{equation*}
		J_{r} = \int_\Omega (\Delta u_\theta+f)^2 \; \text{ and } \; J_{bc} = \int_{\partial\Omega} (u_\theta-g)^2.
	\end{equation*}	
	
	\footnotesize
	\textit{Remark :} In practice, we use a Monte-Carlo method to discretize the cost function by random process.
\end{frame}

\begin{frame}{Simple geometry}
	\textbf{Claim on PINNs :} \textcolor{orange}{No mesh, so easy to go on complex geometry !}
	
	\centering
	\pgfimage[width=0.8\linewidth]{images/content/simple_geom/diapo.jpg}
	
	\flushleft
	\textbf{In practice :} Not so easy ! We need to find \textcolor{orange}{how to sample in the geometry}.
\end{frame}

\begin{frame}{Complex geometry}
	\begin{tabular}{c|c}
		\textbf{1st approach :} \textcolor{orange}{Mapping} & \textbf{2nd approach :} \textcolor{orange}{LevelSet function} \\
		\hline
		\begin{minipage}{0.44\linewidth}
			\textbf{Idea :} \\
			\ding{217} $\Omega_0$ a simple domain (as circle) \\
			\ding{217} $\Omega$ a target domain \\
			\ding{217} A mapping from $\Omega_0$ to $\Omega$ :
			$$\Omega=\phi(\Omega_0)$$
			
			\centering
			\pgfimage[width=0.95\linewidth]{images/content/complex_geom/mapping.jpg}
		\end{minipage} & \begin{minipage}{0.52\linewidth}
			\vspace{4pt}
			\begin{center}
				\pgfimage[width=0.6\linewidth]{images/content/complex_geom/levelset.png}
			\end{center}
			\vspace{-6pt}
			\textbf{Advantages :} \\
			\ding{217} Sample is easy in this case. \\
			\ding{217} Allow to impose in hard the BC :
			\vspace{-10pt}
			\begin{equation*}
				u_\theta(X)=\phi(X)w_\theta(X)+g(X)
			\end{equation*}
			
			\textbf{Natural LevelSet :} \\
			Signed Distance Function (SDF)
			
			\vspace{5pt}
			\textbf{Problem :} SDF is a $\mathcal{C}^0$ function  \\
			$\Rightarrow$ its derivatives explodes \\
			$\Rightarrow$ we \textcolor{orange}{need a regular levelset}
		\end{minipage}
	\end{tabular}
\end{frame}

\begin{frame}[allowframebreaks]{Construct smooth SDF}
		\textbf{1st solution :} \textcolor{orange}{Approximation theory} \cite{sukumar_exact_2022}
		
		$\Delta\phi$ can be singular at the boundary. Sampling at $\epsilon$ to it solve the problem.
		
		\begin{tabular}{c|c}
			\textbf{Polygonal domain} \refappendix{frame:PolygonalDomain} & \textbf{Curved domain} \refappendix{frame:CurvedDomain} \\
			\hline
			\begin{minipage}{0.48\linewidth}
				\flushright
				\pgfimage[width=0.8\linewidth]{images/content/approximation/polygone1.png} \\
				\flushleft
				\pgfimage[width=0.8\linewidth]{images/content/approximation/polygone2.png}
			\end{minipage} & \begin{minipage}{0.48\linewidth}
				\textbf{Minus :} Use of a parametric curve $c(t)$. \\
				\centering
				\pgfimage[width=0.7\linewidth]{images/content/approximation/bean.png}
				
				\pgfimage[width=\linewidth]{images/content/approximation/bean_poisson.jpg}
			\end{minipage}
		\end{tabular}
		
		\newpage
		
		\textbf{2nd solution :} \textcolor{orange}{Learn the levelset.} \cite{clemot_neural_2023} \\
		\ding{217} How make that ? with a \textcolor{orange}{PINNs}.
	
		\begin{tcolorbox}[
			colback=other, % Couleur de fond de la boîte
			colframe=other, % Couleur du cadre de la boîte
			arc=2mm, % Rayon de l'arrondi des coins
			boxrule=0.5pt, % Épaisseur du cadre de la boîte
			breakable, enhanced jigsaw,
			width=\linewidth,
			opacityback=0.1
			]
			
			If we have a boundary domain $\Gamma$, the SDF is solution to the Eikonal equation:
			
			\begin{minipage}{\linewidth}
				\centering
				$\left\{\begin{aligned}
					&||\nabla\phi(X)||=1, \; X\in\mathcal{O} \\
					&\phi(X)=0, \; X\in\Gamma \\
					&\nabla\phi(X)=n, \; X\in\Gamma
				\end{aligned}\right.$
			\end{minipage}
		
			with $\mathcal{O}$ a box which contains $\Omega$ completely and $n$ the exterior normal to $\Gamma$.
		\end{tcolorbox}
		
		\textbf{Advantage :} \textcolor{orange}{No need for parametric curves.}
		
		\begin{minipage}{0.48\linewidth}
			\centering
			\pgfimage[width=0.6\linewidth]{images/content/learn_levelset/points_normals.png}
		\end{minipage} 
		\begin{minipage}{0.48\linewidth}
			\ding{217} set of boundary points \\
			\ding{217} exterior normals at $\Gamma$ \\
			(evaluated at these points)
		\end{minipage}
\end{frame}

\begin{frame}{Learn LevelSet \rom{1}}
	\begin{minipage}{0.78\linewidth}
		\vspace{5pt}
		\textbf{Objective of the paper :} \\
		Learn topological Skeleton (by learning SDF) \quad \refappendix{frame:NeuralSkeleton}
	\end{minipage} \begin{minipage}{0.18\linewidth}	
		\vspace{-30pt}
		\hspace{70pt}\pgfimage[width=0.8\linewidth]{images/content/learn_levelset/skeleton_sans_background.png}
	\end{minipage}
	
	\ding{217} Skeleton correspond exactly to the gradient singularity \\
	\ding{217} Adding the following term in the loss \\
	\begin{minipage}{0.38\linewidth}
		\centering
		$\int_\mathcal{O} ||\nabla||\nabla\phi||(p)||dp$
		\flushright
		(Total Variation Regularization)
	\end{minipage} \quad \begin{minipage}{0.58\linewidth}	
		\vspace{-10pt}
		\flushright
		\pgfimage[width=0.85\linewidth]{images/content/learn_levelset/levelset.jpg}
	\end{minipage}

	\vspace{8pt}

%	\textbf{1st test :} Eikonal equation with TV Regularization \cite{clemot_neural_2023}
%	
%	\begin{minipage}{0.26\linewidth}
%		\pgfimage[width=\linewidth]{images/content/learn_levelset/tv_reg/levelset_loss.jpg}
%	\end{minipage} \quad \begin{minipage}{0.70\linewidth}	
%		\pgfimage[width=\linewidth]{images/content/learn_levelset/tv_reg/levelset.jpg}
%	\end{minipage}

	\begin{minipage}{0.65\linewidth}
		\textbf{1st test :} Eikonal equation with TV Regularization \cite{clemot_neural_2023}
		
		\vspace{25pt}
		\pgfimage[width=1.15\linewidth]{images/content/learn_levelset/tv_reg/levelset.jpg}
	\end{minipage} \begin{minipage}{0.32\linewidth}	
	\vspace{-55pt}
		\pgfimage[width=0.8\linewidth]{images/content/learn_levelset/tv_reg/levelset_loss.jpg}
	\end{minipage}
\end{frame}

\begin{frame}{Learn LevelSet \rom{1}}	
	\begin{minipage}{0.26\linewidth}
		\textbf{Sampling :}
		\begin{center}
			\pgfimage[width=0.8\linewidth]{images/content/learn_levelset/tv_reg/sampling_with_v.jpg}
		\end{center}
	\end{minipage} \quad \begin{minipage}{0.70\linewidth}
		\centering
		\pgfimage[width=0.8\linewidth]{images/content/learn_levelset/tv_reg/classical_pinns.jpg}
		
		\footnotesize\flushleft\vspace{-10pt}
		\qquad\qquad \textbf{Minus :} Costly boundary points generation.
	\end{minipage}
	
	\vspace{10pt}
	
	\textbf{PINNs - Impose BC in hard :} Looking for $u_\theta=\phi w_\theta$.
	\begin{center}
		\pgfimage[width=0.7\linewidth]{images/content/learn_levelset/tv_reg/levelset_derivatives.png}
	\end{center}
	
	\vspace{-10pt}
	Levelset derivatives explode.
\end{frame}

\begin{frame}{Learn LevelSet \rom{2}}
	\textbf{2nd test :} We replace the TV term by a penalization on the laplacian of the levelset
%	\begin{equation*}
%		J_{reg}=\int_{\mathcal{O}} |\Delta \phi|^2
%	\end{equation*}

	\begin{center}
		\pgfimage[width=0.6\linewidth]{images/content/learn_levelset/lap_reg/levelset_reg.jpg}
	\end{center}

	\begin{minipage}{0.28\linewidth}
		\centering
		\textbf{Sampling :}
		
		\pgfimage[width=0.7\linewidth]{images/content/learn_levelset/lap_reg/sampling_with_v.png}
	\end{minipage} \quad \begin{minipage}{0.68\linewidth}
		\centering
		\textbf{Dirichlet error on the boundary :}
		
		\pgfimage[width=0.5\linewidth]{images/content/learn_levelset/lap_reg/dirichlet.png}
	\end{minipage}


\end{frame}

\begin{frame}{Learn LevelSet \rom{2}}
	\textbf{Derivatives :}

	\begin{center}
		\pgfimage[width=0.6\linewidth]{images/content/learn_levelset/lap_reg/levelset_derivatives.png}
	\end{center}
	
	 $\Rightarrow$ \textcolor{orange}{We can impose in hard boundary conditions}
	
	\textbf{PINNs - Impose BC in hard :} Looking for $u_\theta=\phi w_\theta$.
	\begin{center}
		\pgfimage[width=0.7\linewidth]{images/content/learn_levelset/lap_reg/poisson_with_v.jpg}
	\end{center}
\end{frame}